# habrCrawler
Собирает новости с хабра, гиктаймс и мегамозга в .csv файл. По умолчанию в 7й винде валится в Документы.

Отслеживание авторов по умолчанию выключено, при необходимости исправить стр. 20 на 'traceAuthors = TRUE'

Написано на R, потому что он оказался под рукой, плюс реализация довольно тормозная — точно не подумают, что это DDoS )
Просматривает все страницы, на которых есть новости за последние dayShift дней. Если язык системы не русский, надо подлатать вектор monthConvert.

Обработка новостей в каждом цикле (для каждого из сайтов) прописана отдельно, хотя код тот же самый, потому что одно время к сайтам приходилось обращаться по разному. Так с тех пор и осталось.

Большая часть написана уже и не помню когда, на исправление индусского кода жалко времени.

## Использование
Настроить пути:
```
where = "" # путь до папки с файлами
outFile = "" # файл для записи
authorsListSrc = "" # файл со списком авторов, статьи которых надо отслеживать - выделяются '@@@ ' перед заголовком
traceAuthors = TRUE # включить отслеживание авторов
```
Запуск парсера:
```
readHabr("http://habrahabr.ru/all/")
readHabr("http://geektimes.ru/hub/google/", startFrom = 1, limitNumber = 20, dayShift = 107)
# startFrom - начать со страницы (по умолчанию 1)
# limitNumber - ограничить количество страниц (по умолчанию выключено)
# dayShift - смотреть за последние n дней (по умолчанию 7)
```
Работает со всеми ресурсами на хабре, гиктаймс, мегамозге, имеющими форму "ресурс/page{n}"
